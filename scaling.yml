- hosts: cluster_login
  become: yes
  vars:
    venv: "{{ playbook_dir }}/.venv/bin/activate"
    tf_compute_resource: "openstack_compute_instance_v2" # terraform "resource type" of compute instances
    tf_lock_timeout: 240 # number of seconds to retry terraform operations if state file locked
  tasks:
    - name: get deployment user name
      become: false
      local_action: command whoami
      register: ansible_host_whoami
    - set_fact: ansible_host_username="{{ansible_host_whoami.stdout_lines[0]}}"
    - debug:
        var: ansible_host_username
    - name: setup an ssh key for (existing) slurm user
      user:
        name: slurm
        shell: /bin/bash # don't like this, was /sbin/nologin but need to run ssh
        create_home: yes # default, but needs creating
        generate_ssh_key: yes
      register: slurm_user
    - name: slurp slurm key
      slurp:
        src: "{{ slurm_user.home }}/.ssh/id_rsa.pub"
      register: slurmkey
    - set_fact:
        slurm_key: "{{ slurmkey.content | b64decode | replace('\n', '') }}"
    - name: create resume script
      template:
        src: slurmscripts/resume.j2
        dest: "{{ slurm_user.home }}/resume.sh"
        owner: slurm
        mode: 0744
    - name: create suspend script
      template:
        src: slurmscripts/suspend.j2
        dest: "{{ slurm_user.home }}/suspend.sh"
        owner: slurm
        mode: 0744
    - name: Get ansible/tf control host's SSH key
      command: "ssh-keyscan -t rsa {{ control_host }}"
      register: control_host_keys
      changed_when: False
    - name: add ansible/tf control host's keys to known hosts
      blockinfile:
        block: |
          {% for line in control_host_keys.stdout_lines %}
          {{ line }}
          {% endfor %}
        create: true
        marker: "# {mark} MANAGED BLOCK FOR ansible control host"
        path: "{{ slurm_user.home }}/.ssh/known_hosts"
#      loop: "{{ hostvars['localhost']['ssh_keys'] }}"
      
- hosts: localhost
  tasks:
    - name: add slurm login node key to localhost authorised keys
      lineinfile:
        path: /home/{{ ansible_user }}/.ssh/authorized_keys # fragile for user home directory location?
        state: present
        line: "{{ hostvars['ohpc-login']['slurm_key'] }}" # TODO: not sure this is the right way to ref this host??
        #regexp: "{{ hostvars['ohpc-login']['slurm_key'] }}"
    - name: create scale script on ansible/tf control host
      template:
        src: "{{ playbook_dir }}/slurmscripts/scale.j2"
        dest: "{{ playbook_dir }}/slurmscripts/scale.py"
        #owner: "{{ ansible_user }}"
        mode: 0744
        
- hosts:
  - cluster_control
  - cluster_batch
  become: yes
  tasks:
    - name: Ensure Slurm services are running
      service:
        name: "{{ openhpc_slurm_service }}"
        state: "started"
      when:
        - openhpc_slurm_service is defined
        - openhpc_slurm_service is not none
